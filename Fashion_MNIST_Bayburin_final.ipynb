{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion MNIST Bayburin final.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BSpekter/Special-Public/blob/master/Fashion_MNIST_Bayburin_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HObyqUY4Wu0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets,transforms\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXJ7CpREe5FT",
        "colab_type": "text"
      },
      "source": [
        "Как говорил Лектор, наверное стоит внести ссылки на источники, ибо так не совсем научно. Постараемся так и сделать.\n",
        "\n",
        "\n",
        "\n",
        "Большая благодарность чувствуется вот тут:\n",
        "\n",
        "https://towardsdatascience.com/building-neural-network-using-pytorch-84f6e75f9a\n",
        "\n",
        "https://towardsdatascience.com/training-a-neural-network-using-pytorch-72ab708da210\n",
        "\n",
        "Часть кода реализовано от этого источника \n",
        "https: //www.arunprakash.org/2018/12/cnn-fashion-mnist-dataset-pytorch.html\n",
        "\n",
        "Вдохновение пару раз посещало и на этом сайте:\n",
        "https://www.kaggle.com/swapnil2195/part-4-fashion-mnist-solution/data\n",
        "\n",
        "Красивый код временами созерцался тут: https://necromuralist.github.io/In-Too-Deep/posts/nano/pytorch/part-4-fashion/\n",
        "\n",
        "Вот это точно можно потом посмотреть: https://github.com/mayurbhangale/fashion-mnist-pytorch/blob/master/CNN_Fashion_MNIST.ipynb\n",
        "\n",
        "CNN ресурс тут: https://github.com/kishankg/2-Layer-CNN-with-Pytorch-Fashion-MNIST-/blob/master/2%20Layer%20CNN%20with%20Pytorch%20(Fashion-MNIST).ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95YqsbJKUVWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, ), (0.5, ))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5Cn4VUHUX6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', train = True, transform=transform, download=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdFM2T26UaoL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, shuffle=True, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvlf6loMUnAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', train = False, transform=transform, download = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuI3cMZLUqSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testloader = torch.utils.data.DataLoader(testset, shuffle=False, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK6eNDnzcX2X",
        "colab_type": "text"
      },
      "source": [
        "Попробовал поиграть с обычной полносвязной нейросетью. Конечно не 92% Accuracy, но тоже ничего. И конечно стоит сказать что Dropout помогает.\n",
        "\n",
        "Да и попробовал применить Adam and SGD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLJn_7dFT5B4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(784, 256)\n",
        "        self.l2 = nn.Linear(256, 128)\n",
        "        self.l3 = nn.Linear(128,64)\n",
        "        self.l4 = nn.Linear(64,10)\n",
        "    def forward(self,x):\n",
        "        #So here we are trying to flatten images along vector\n",
        "        x = x.view(x.shape[0],-1)\n",
        "\n",
        "        x = F.relu(self.l1(x))\n",
        "        x = F.relu(self.l2(x))\n",
        "        x = F.relu(self.l3(x))\n",
        "        x = F.log_softmax(self.l4(x), dim=1)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMJktsp0b7nk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model=Model().to(device)\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEZPLW7WcCGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch = 30\n",
        "train_losses, test_losses = [],[]\n",
        "for e in range(epoch):\n",
        "    train_loss = 0\n",
        "    test_loss = 0\n",
        "    accuracy = 0\n",
        "    for images, labels in trainloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for images,labels in testloader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                log_ps = model(images)\n",
        "                prob = torch.exp(log_ps)\n",
        "                top_probs, top_classes = prob.topk(1, dim=1)\n",
        "                equals = labels == top_classes.view(labels.shape)\n",
        "                accuracy += equals.type(torch.FloatTensor).mean()\n",
        "                test_loss += criterion(log_ps, labels)\n",
        "        model.train()\n",
        "    print(\"Epoch: {}/{}.. \".format(e+1, epoch),\n",
        "              \"Training Loss: {:.3f}.. \".format(train_loss/len(trainloader)),\n",
        "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
        "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
        "    train_losses.append(train_loss/len(trainloader))\n",
        "    test_losses.append(test_loss/len(testloader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10l6OPP-eJvS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(train_losses,label = \"Train losses\")\n",
        "plt.plot(test_losses, label = \"Test losses\")\n",
        "plt.title(\"Here we use SGD algorithm\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXrWIFHaPh-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZLis8GpRghC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch = 30\n",
        "train_losses, test_losses = [],[]\n",
        "for e in range(epoch):\n",
        "    train_loss = 0\n",
        "    test_loss = 0\n",
        "    accuracy = 0\n",
        "    for images, labels in trainloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for images,labels in testloader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                log_ps = model(images)\n",
        "                prob = torch.exp(log_ps)\n",
        "                top_probs, top_classes = prob.topk(1, dim=1)\n",
        "                equals = labels == top_classes.view(labels.shape)\n",
        "                accuracy += equals.type(torch.FloatTensor).mean()\n",
        "                test_loss += criterion(log_ps, labels)\n",
        "        model.train()\n",
        "    print(\"Epoch: {}/{}.. \".format(e+1, epoch),\n",
        "              \"Training Loss: {:.3f}.. \".format(train_loss/len(trainloader)),\n",
        "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
        "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
        "    train_losses.append(train_loss/len(trainloader))\n",
        "    test_losses.append(test_loss/len(testloader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_IjeaLfe3yA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(train_losses,label = \"Train losses\")\n",
        "plt.plot(test_losses, label = \"Test losses\")\n",
        "plt.title(\"Here we use Adam algorithm\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iivxbTDWfCOj",
        "colab_type": "text"
      },
      "source": [
        "**Model with dropout**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8e5RaMjfB0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(784, 256)\n",
        "        self.l2 = nn.Linear(256, 128)\n",
        "        self.l3 = nn.Linear(128,64)\n",
        "        self.l4 = nn.Linear(64,10)\n",
        "        \n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "    def forward(self,x):\n",
        "        x = x.view(x.shape[0],-1)\n",
        "        \n",
        "        x = self.dropout(F.relu(self.l1(x)))\n",
        "        x = self.dropout(F.relu(self.l2(x)))\n",
        "        x = self.dropout(F.relu(self.l3(x)))\n",
        "        x = F.log_softmax(self.l4(x), dim=1)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJnzUClgfOKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model().to(device)\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26UTtIZSRuVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch = 30\n",
        "train_losses, test_losses = [],[]\n",
        "for e in range(epoch):\n",
        "    train_loss = 0\n",
        "    test_loss = 0\n",
        "    accuracy = 0\n",
        "    for images, labels in trainloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for images,labels in testloader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                log_ps = model(images)\n",
        "                prob = torch.exp(log_ps)\n",
        "                top_probs, top_classes = prob.topk(1, dim=1)\n",
        "                equals = labels == top_classes.view(labels.shape)\n",
        "                accuracy += equals.type(torch.FloatTensor).mean()\n",
        "                test_loss += criterion(log_ps, labels)\n",
        "        model.train()\n",
        "    print(\"Epoch: {}/{}.. \".format(e+1, epoch),\n",
        "              \"Training Loss: {:.3f}.. \".format(train_loss/len(trainloader)),\n",
        "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
        "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
        "    train_losses.append(train_loss/len(trainloader))\n",
        "    test_losses.append(test_loss/len(testloader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlVpc7-bfeFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(train_losses,label = \"Train losses\")\n",
        "plt.plot(test_losses, label = \"Test losses\")\n",
        "plt.title(\"Adam model with Dropout\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXiElijs-ly0",
        "colab_type": "text"
      },
      "source": [
        "Как видно, модель с Dropout ведёт себя лучше, пусть и не значительно.\n",
        "\n",
        "Если я правильно понимаю, то дальше мы докажем что полносвязные сети проигрывают CNN в точности работы в задаче \"классификации картинок\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F1q6TtZpjQd",
        "colab_type": "text"
      },
      "source": [
        "**Попытаемся построить CNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok90DEdRqukZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 30\n",
        "num_classes = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWDpfRfcDwmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self,num_classes=10):\n",
        "        super(CNN, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        self.fc = nn.Linear(7*7*32, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzgjdyUpqFCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Fx7OESCC5ao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_and_plot(model, num_epochs, criterion, optimizer):\n",
        "    train_loss, test_loss = [], []\n",
        "    for e in range(num_epochs):\n",
        "        start_time = time.time()\n",
        "\n",
        "        trloss = 0\n",
        "        teloss = 0\n",
        "\n",
        "        model.train(True)\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            #Run the model\n",
        "            output = model(images)\n",
        "            loss = criterion(output, labels)\n",
        "            trloss += loss.item()\n",
        "\n",
        "            #Backprop and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.train(False)\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            output = model(images)\n",
        "            loss = criterion(output, labels)\n",
        "            teloss += loss.item()\n",
        "\n",
        "        train_loss.append(trloss/len(trainloader))\n",
        "        test_loss.append(teloss/len(testloader))\n",
        "\n",
        "        #Printing results for the epoch\n",
        "        print(\"Epoch {} of {} took {:.3f}s\".format(e+1, num_epochs,\n",
        "                                                  time.time()-start_time))\n",
        "        print(\"Training loss in this epoch: \\t{:.6f}\".format(train_loss[-1]))\n",
        "\n",
        "    plt.plot(train_loss, label=\"Train loss\")\n",
        "    plt.plot(test_loss, label=\"Test loss\")\n",
        "    plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaV-XO7VrREj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_accuracy(model):\n",
        "    model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            images = Variable(images.float())\n",
        "            labels = Variable(labels)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print('Test Accuracy of the model: {} %'.format(100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swyl7LcVY8hs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " test_and_plot(model, 30, criterion, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E__9Ku7prYjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_accuracy(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRV-Pgw-EsPC",
        "colab_type": "text"
      },
      "source": [
        "Думаю тут можно сказать что lr для этой модели слишком высок.\n",
        "\n",
        "Теперь попробуем модифицировать модель добавив Dropout и Batch normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMkZUqCRExPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self,num_classes=10):\n",
        "        super(CNN, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        self.fc = nn.Linear(7*7*32, 10)\n",
        "        self.Dropout = nn.Dropout(p=0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.Dropout(F.relu(self.fc(out)))\n",
        "        return out\n",
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ydb78uKsVTwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5h18163aVku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_and_plot(model, 30, criterion, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB14gp8fEJ4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_accuracy(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pktU5wQ1GQBF",
        "colab_type": "text"
      },
      "source": [
        "Решили проблему - потеряли Accuracy. Видимо в дальнейшем нужно просто модифицировать параметры.\n",
        "\n",
        "В общем случае поняли что добавленные нами методы работают. Сейчас придумаем новую модель для достижения Accuracy > 92%.\n",
        "\n",
        "Буду надеятся что ключ к упеху - Дропауты, Батчнорм и больше слоёв."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FATb45OfdQ5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            )\n",
        "        self.fc1 = nn.Linear(128*49, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "        self.LogSoftmax = nn.LogSoftmax( dim=1)\n",
        "\n",
        "        self.Dropout = nn.Dropout(p=0.3)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.Dropout(self.layer2(out))\n",
        "        out = self.layer3(out)\n",
        "\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = self.Dropout(self.fc2(out))\n",
        "        out = self.LogSoftmax(self.fc3(out))\n",
        "        return out\n",
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z2yhJ05U9M9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_and_plot(model, 30, criterion, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZKY8LOvVCkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_accuracy(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iko_kBlgHCf",
        "colab_type": "text"
      },
      "source": [
        "Цели по Accuracy достигли, попробуем сделать лучше."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYnEUougfrs5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU()\n",
        "            )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU()\n",
        "            )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU()\n",
        "            )\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            )\n",
        "        self.fc1 = nn.Linear(25088, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "        self.LogSoftmax = nn.LogSoftmax(dim=1)\n",
        "        self.Dropout = nn.Dropout(p=0.3)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.Dropout(self.layer2(out))\n",
        "        out = self.Dropout(self.layer3(out))\n",
        "        out = self.Dropout(self.layer4(out))\n",
        "\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = self.LogSoftmax(self.fc2(out))\n",
        "        return out\n",
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMbgqZUOhx_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_and_plot(model, 30, criterion, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDTCpc-ykGE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_accuracy(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFRtaDMjkZCk",
        "colab_type": "text"
      },
      "source": [
        "Получилось не сильно лучше.\n",
        "Думаю в целом задание выполнено."
      ]
    }
  ]
}